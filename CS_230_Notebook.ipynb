{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS 230 Notebook",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leilaelise/CS230_Final_Project/blob/main/CS_230_Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tteo4r95Rm00"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K08s5H2sRpez",
        "outputId": "2a9eb408-9a07-43a2-92ba-1318c07c153a"
      },
      "source": [
        "!git clone https://github.com/dougsm/ggcnn.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'ggcnn'...\n",
            "remote: Enumerating objects: 124, done.\u001b[K\n",
            "remote: Total 124 (delta 0), reused 0 (delta 0), pack-reused 124\u001b[K\n",
            "Receiving objects: 100% (124/124), 44.88 KiB | 1.87 MiB/s, done.\n",
            "Resolving deltas: 100% (45/45), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e84EiLHqSrTz",
        "outputId": "924602e9-9785-45a6-901c-545bd9a4f342"
      },
      "source": [
        "%cd /content/ggcnn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/ggcnn\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZa97zI6S0cT",
        "outputId": "cb9f69e5-9ab8-4a5d-b4a1-b203f455b988"
      },
      "source": [
        "!pip install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (1.19.5)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (4.1.2.30)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (3.2.2)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (0.16.2)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (2.4.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (1.8.1+cu101)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (0.9.1+cu101)\n",
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 8)) (1.5.1)\n",
            "Collecting tensorboardX\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/84/46421bd3e0e89a92682b1a38b40efc22dafb6d8e3d947e4ceefd4a5fabc7/tensorboardX-2.2-py2.py3-none-any.whl (120kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 14.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 3)) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 3)) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 3)) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 3)) (2.4.7)\n",
            "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->-r requirements.txt (line 4)) (1.4.1)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->-r requirements.txt (line 4)) (7.1.2)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->-r requirements.txt (line 4)) (1.1.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->-r requirements.txt (line 4)) (2.5.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->-r requirements.txt (line 6)) (3.7.4.3)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX->-r requirements.txt (line 9)) (3.12.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->-r requirements.txt (line 3)) (1.15.0)\n",
            "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx>=2.0->scikit-image->-r requirements.txt (line 4)) (4.4.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorboardX->-r requirements.txt (line 9)) (57.0.0)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hLa5oofpnT0k",
        "outputId": "a5b7fe75-4a1d-4eae-df51-ff55cfeae254"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TedmhIwafuxk",
        "outputId": "b223b822-42a7-4d75-b82f-6bcd08d7187b"
      },
      "source": [
        "import torch\n",
        "model = torch.load('/content/drive/MyDrive/Colab_Notebooks/ggcnn_weights_cornell/ggcnn_epoch_23_cornell')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/serialization.py:656: SourceChangeWarning: source code of class 'torch.nn.modules.conv.Conv2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
            "  warnings.warn(msg, SourceChangeWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/serialization.py:656: SourceChangeWarning: source code of class 'torch.nn.modules.conv.ConvTranspose2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
            "  warnings.warn(msg, SourceChangeWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHU2qPaqjwvf",
        "outputId": "52d1c6d0-c63d-4246-c4da-f17463d0b137"
      },
      "source": [
        "#Random Search initialization\n",
        "#Define 4 random hyperparameters to begin the search space for the optimal hyperparameters\n",
        "%matplotlib inline\n",
        "import numpy as np \n",
        "#Random search implementation for hyperparameter tuning\n",
        "\n",
        "for i in range(4):\n",
        "  num_epochs = np.random.randint(1,5)\n",
        "  num_batches_per = np.random.randint(500,2000)\n",
        "  batchSize = np.random.randint(1,20)\n",
        "  split = np.random.uniform(0.7,0.9)\n",
        "  print(num_epochs,num_batches_per,batchSize,split)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 797 3 0.797604057780065\n",
            "2 707 19 0.7120108205659341\n",
            "3 540 3 0.851600785800768\n",
            "1 880 17 0.7891576907435942\n",
            "3 1419 4 0.7763308958723835\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nCcC5w3U-eLO",
        "outputId": "77905691-6791-4fb9-a970-efdae461ccde"
      },
      "source": [
        "!python3 train_ggcnn.py --network ggcnn --dataset cornell --dataset-path '/content/drive/MyDrive/Colab_Notebooks/archive' --epochs 5 --batches-per-epoch 1217 --batch-size 14  --split 0.815\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:root:Loading Cornell Dataset...\n",
            "INFO:root:Done\n",
            "INFO:root:Loading Network...\n",
            "INFO:root:Done\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 32, 100, 100]           2,624\n",
            "            Conv2d-2           [-1, 16, 50, 50]          12,816\n",
            "            Conv2d-3            [-1, 8, 25, 25]           1,160\n",
            "           Dropout-4            [-1, 8, 25, 25]               0\n",
            "   ConvTranspose2d-5            [-1, 8, 50, 50]             584\n",
            "   ConvTranspose2d-6         [-1, 16, 100, 100]           3,216\n",
            "           Dropout-7         [-1, 16, 100, 100]               0\n",
            "   ConvTranspose2d-8         [-1, 32, 301, 301]          41,504\n",
            "            Conv2d-9          [-1, 1, 300, 300]             129\n",
            "           Conv2d-10          [-1, 1, 300, 300]             129\n",
            "           Conv2d-11          [-1, 1, 300, 300]             129\n",
            "           Conv2d-12          [-1, 1, 300, 300]             129\n",
            "================================================================\n",
            "Total params: 62,420\n",
            "Trainable params: 62,420\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.34\n",
            "Forward/backward pass size (MB): 30.28\n",
            "Params size (MB): 0.24\n",
            "Estimated Total Size (MB): 30.86\n",
            "----------------------------------------------------------------\n",
            "INFO:root:Beginning Epoch 00\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 517, in __next__\n",
            "    data = self._next_data()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1182, in _next_data\n",
            "    idx, data = self._get_data()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1148, in _get_data\n",
            "    success, data = self._try_get_data()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 986, in _try_get_data\n",
            "    data = self._data_queue.get(timeout=timeout)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 104, in get\n",
            "    if not self._poll(timeout):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 257, in poll\n",
            "    return self._poll(timeout)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 414, in _poll\n",
            "    r = wait([self], timeout)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 921, in wait\n",
            "    ready = selector.select(timeout)\n",
            "  File \"/usr/lib/python3.7/selectors.py\", line 415, in select\n",
            "    fd_event_list = self._selector.poll(timeout)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"train_ggcnn.py\", line 285, in <module>\n",
            "    lossPlot,epochs,best_iou, batches_per_epoch = run()\n",
            "  File \"train_ggcnn.py\", line 254, in run\n",
            "    train_results,lossVec = train(epoch, net, device, train_data, optimizer, args.batches_per_epoch, vis=args.vis)               \n",
            "  File \"train_ggcnn.py\", line 145, in train\n",
            "    for x, y, _, _, _ in train_data:\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 517, in __next__\n",
            "    data = self._next_data()\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jzUYSvFX500w",
        "outputId": "b330348c-b193-46e7-8446-d7a3847c38c0"
      },
      "source": [
        "!python3 eval_ggcnn.py --network '/content/ggcnn/output/models/210603_1830_/epoch_04_iou_0.69' --dataset cornell --dataset-path '/content/drive/MyDrive/Colab_Notebooks/archive' --iou-eval "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:root:Loading Cornell Dataset...\n",
            "INFO:root:Done\n",
            "INFO:root:Processing 1/89\n",
            "INFO:root:Processing 2/89\n",
            "INFO:root:Processing 3/89\n",
            "INFO:root:Processing 4/89\n",
            "INFO:root:Processing 5/89\n",
            "INFO:root:Processing 6/89\n",
            "INFO:root:Processing 7/89\n",
            "INFO:root:Processing 8/89\n",
            "INFO:root:Processing 9/89\n",
            "INFO:root:Processing 10/89\n",
            "INFO:root:Processing 11/89\n",
            "INFO:root:Processing 12/89\n",
            "INFO:root:Processing 13/89\n",
            "INFO:root:Processing 14/89\n",
            "INFO:root:Processing 15/89\n",
            "INFO:root:Processing 16/89\n",
            "INFO:root:Processing 17/89\n",
            "INFO:root:Processing 18/89\n",
            "INFO:root:Processing 19/89\n",
            "INFO:root:Processing 20/89\n",
            "INFO:root:Processing 21/89\n",
            "INFO:root:Processing 22/89\n",
            "INFO:root:Processing 23/89\n",
            "INFO:root:Processing 24/89\n",
            "INFO:root:Processing 25/89\n",
            "INFO:root:Processing 26/89\n",
            "INFO:root:Processing 27/89\n",
            "INFO:root:Processing 28/89\n",
            "INFO:root:Processing 29/89\n",
            "INFO:root:Processing 30/89\n",
            "INFO:root:Processing 31/89\n",
            "INFO:root:Processing 32/89\n",
            "INFO:root:Processing 33/89\n",
            "INFO:root:Processing 34/89\n",
            "INFO:root:Processing 35/89\n",
            "INFO:root:Processing 36/89\n",
            "INFO:root:Processing 37/89\n",
            "INFO:root:Processing 38/89\n",
            "INFO:root:Processing 39/89\n",
            "INFO:root:Processing 40/89\n",
            "INFO:root:Processing 41/89\n",
            "INFO:root:Processing 42/89\n",
            "INFO:root:Processing 43/89\n",
            "INFO:root:Processing 44/89\n",
            "INFO:root:Processing 45/89\n",
            "INFO:root:Processing 46/89\n",
            "INFO:root:Processing 47/89\n",
            "INFO:root:Processing 48/89\n",
            "INFO:root:Processing 49/89\n",
            "INFO:root:Processing 50/89\n",
            "INFO:root:Processing 51/89\n",
            "INFO:root:Processing 52/89\n",
            "INFO:root:Processing 53/89\n",
            "INFO:root:Processing 54/89\n",
            "INFO:root:Processing 55/89\n",
            "INFO:root:Processing 56/89\n",
            "INFO:root:Processing 57/89\n",
            "INFO:root:Processing 58/89\n",
            "INFO:root:Processing 59/89\n",
            "INFO:root:Processing 60/89\n",
            "INFO:root:Processing 61/89\n",
            "INFO:root:Processing 62/89\n",
            "INFO:root:Processing 63/89\n",
            "INFO:root:Processing 64/89\n",
            "INFO:root:Processing 65/89\n",
            "INFO:root:Processing 66/89\n",
            "INFO:root:Processing 67/89\n",
            "INFO:root:Processing 68/89\n",
            "INFO:root:Processing 69/89\n",
            "INFO:root:Processing 70/89\n",
            "INFO:root:Processing 71/89\n",
            "INFO:root:Processing 72/89\n",
            "INFO:root:Processing 73/89\n",
            "INFO:root:Processing 74/89\n",
            "INFO:root:Processing 75/89\n",
            "INFO:root:Processing 76/89\n",
            "INFO:root:Processing 77/89\n",
            "INFO:root:Processing 78/89\n",
            "INFO:root:Processing 79/89\n",
            "INFO:root:Processing 80/89\n",
            "INFO:root:Processing 81/89\n",
            "INFO:root:Processing 82/89\n",
            "INFO:root:Processing 83/89\n",
            "INFO:root:Processing 84/89\n",
            "INFO:root:Processing 85/89\n",
            "INFO:root:Processing 86/89\n",
            "INFO:root:Processing 87/89\n",
            "INFO:root:Processing 88/89\n",
            "INFO:root:Processing 89/89\n",
            "INFO:root:IOU Results: 59/89 = 0.662921\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOZFIScyhX8o",
        "outputId": "239ff073-9d65-4868-bdec-238a103888a7"
      },
      "source": [
        "#Cross entropy optimization for hyperparamter tuning \n",
        "\n",
        "import numpy as np\n",
        "#Take the two elite samples, defined by accuracy \n",
        "mu = np.array([[5,1471,13,0.731],[5,863,16,0.9]])\n",
        "\n",
        "#Compute MLE estimation of the elite samples \n",
        "sigma_new = np.array([0,0,0,0])\n",
        "mu_new = np.array([5,1167,14,0.815])\n",
        "\n",
        "#Compute new standard deviation\n",
        "for j in range(2):\n",
        "  for i in range(4):\n",
        "    sigma_new[i] = 0.5*(mu[j][i] - mu_new[i])**2\n",
        "\n",
        "stdv = np.sqrt(sigma_new)\n",
        "\n",
        "#Determine hyperparameters drawn from the updated normal distribution\n",
        "print(np.random.normal(mu_new,stdv))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[5.00000000e+00 1.26845838e+03 1.71429498e+01 8.15500000e-01]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}